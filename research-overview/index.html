<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.1.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Rohan V Kashyap" />

  
  
  
    
  
  <meta name="description" content="High-level overview of research interests." />

  
  <link rel="alternate" hreflang="en-us" href="https://rohanvkashyap.github.io/research-overview/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather%7CRoboto+Mono&display=swap">
      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.0a609407e817c1ae97edbc32c7cd0281.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-48275004-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-48275004-1', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  

  

  




  
  
  

  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hufdd866d90d76849587aac6fbf27da1ac_464_32x32_fill_lanczos_center_2.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hufdd866d90d76849587aac6fbf27da1ac_464_180x180_fill_lanczos_center_2.png" />

  <link rel="canonical" href="https://markvdw.github.io/research-overview/" />

  
  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary" />
  
  <meta property="og:site_name" content="Rohan V Kashyap" />
  <meta property="og:url" content="https://rohanvkashyap.github.io/research-overview/" />
  <meta property="og:title" content="Research Overview | Rohan V Kashyap" />
  <meta property="og:description" content="High-level overview of research interests." /><meta property="og:image" content="https://markvdw.github.io/media/icon_hufdd866d90d76849587aac6fbf27da1ac_464_512x512_fill_lanczos_center_2.png" />
    <meta property="twitter:image" content="https://markvdw.github.io/media/icon_hufdd866d90d76849587aac6fbf27da1ac_464_512x512_fill_lanczos_center_2.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2022-01-04T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2022-01-04T00:00:00&#43;00:00">
  

  



  

  

  





  <title>Research Overview | Rohan V Kashyap</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="68d5def351fb4241a87b2f02b7b1e96c" >

  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.f16be01fc8fb2b5885dd67ce942d1185.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Rohan V Kashyap</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Rohan V Kashyap</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <!--<li class="nav-item">
          <a class="nav-link " href="/people/"><span>Group</span></a>
        </li>-->

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link  active" href="/research-overview/"><span>Research Overview</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <!--<li class="nav-item">
          <a class="nav-link " href="/teaching/"><span>Teaching</span></a>
        </li>-->

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#talks"><span>Talks</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/publication/"><span>Publications</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
      

      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Research Overview</h1>

  
  <p class="page-subtitle">A high-level overview of our research interests</p>
  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
    Rohan V Kashyap</span>
  </div>
  
  

  

  

  

  
  
  
  
  
  

  
  

</div>

    





  
</div>



  <div class="article-container">

    <div class="article-style">
      <h2 id="list-of-research-interests">List of Research Interests</h2>
<ul>
<li>Poisson Flow generative models.</li>
<li>Variational Diffusion models.</li>
<!--li>Mathematical reasoning for theorem proving using neural nets.</li-->
<!--li>Analysis of deep neural networks (infinite limits and GP relations). </li-->
<li>Direct and indirect push-forward generative models. Eg: VAE, GAN and diffusion models.</li>
<li>Neural networks with invariance properties (e.g. rotation, scale, or more arbitrary) and learning invariances for continuous image manifolds.</li>
<!--li>Analysis of neural network optimization in the weight space and related topics (convergence rates, cyclic step sizes, chebyshev polynomials, residual polynomials and link functions) for gradient descent algorithm.</li-->
</ul>
<!--<h2 id="high-level-aims-and-approach">High-level aims and approach</h2>
<p>Our research aims to improve three broad properties of Machine Learning methods:</p>
<ul>
<li>Data efficiency: Making better predictions with less data.</li>
<li>Automatic Machine Learning: Methods are too brittle, and require human design and oversight.</li>
<li>Uncertainty quantification and decision making: Uncertainty tells us when risks are worth taking.</li>
</ul>
<p>Improvements in these areas would benefit the full spectrum of applications: from tasks with small amounts of data where eliminating noise is important, to high-dimensional large-data settings where neural networks are applied to natural data like images.</p>
<p>I&rsquo;m not completely sure what approach I would bet on. I certainly follow developments in meta-learning and large models carefully. If the answer to this was clear, this wouldn&rsquo;t be research. Luckily, there are interesting questions to investigate in both directions.</p>-->
<h2 id="research-highlights">Research Highlights</h2>
<p>To give a more concrete idea of research we have done, here are some projects and papers roughly grouped together in themes.</p>
<h3 id="learning-invariances">Learning invariances</h3>
<figure>
  <img src="/poster.png" alt=""/>
  <figcaption>Figure: AISTATS Poster.</figcaption>
</figure>
<p>Invariance and equivariance are very common inductive biases, with the ubiquitous convolutional layer being the most common example. When designing architectures, humans currently choose how many convolutional layers to use, together with parameters like filter size. Often these choices are made with a laborious trial-and-error procedure (cross-validation). To make the number of choices even larger, other types of convolutional layers have been developed in recent years, which help generalisation across different scales and rotations. The optimal inductive bias varies by problem and dataset, so it would be nice if we had an automatic procedure for determining these.</p>
<p>We are developing methods that allow weights and architecture to be learned <em>at the same time</em>, by optimising a single objective function. In our paper <a href="https://rohanvkashyap.github.io/authors/admin/Neural%20discovery%20of%20permutation%20subgroups.pdf"><em>Neural discovery of permutation subgroups</em></a> (AISTATS 2023) we present a novel method to discover the underlying subgroup, given that it satisfies certain conditions. Our results show that one could discover any subgroup of type <span class="math inline">\(S_k(k \leq n)\)</span> by learning an <span class="math inline">\(S_n\)</span>-invariant function and a linear transformation.</p>
<!--<p>The final invariance can be visualised by looking at the samples that the data augmentation procedure generates. Samples generated for a particular input image visualise which transformations are seen as not changing the label (see figure below).</p>
<p>Overall, this procedure is a lot more convenient than training a model many times in a cross-validated grid search over the data augmentation parameters. What really shows that invariances are truly learned here, is that if you apply the <em>same</em> method to a dataset with different characteristics, a different invariance is learned. The same exact method that worked well on MNIST would learn almost full rotational invariance for rotated MNIST (see paper for results). Following the normal procedure, the cross-validated grid search would have to be performed again!</p>-->
<!--<figure>
  <img src="/authors/admin/DALLE-2-IMAGES.png" alt=""/>
  <figcaption>Figure: Selected samples from DALLE-2 model.</figcaption>
</figure>-->
<!--<p>What are the limitations?</p>
<ul>
<li>Currently it only works really robustly on shallow models (although we have had <a href="/publication/schwoebel-2021-layer/">partial progress in deep models</a>).</li>
<li>You need to specify a solution space of invariances, from which the correct invariance is picked. All machine learning methods need to parameterise their solution space, but so far we have only parameterised simple ones like the space of distributions on affine transformations, and local deformations.</li>
</ul>-->
<h3 id="A Unified Framework for Discovering Discrete Symmetries">A Unified Framework for Discovering Discrete Symmetries</h3>
<p></p>In our recent paper, <a href="https://rohanvkashyap.github.io/authors/admin/view_1.pdf"><em>A Unified Framework for Discovering Discrete Symmetries</em></a> (NeurIPS review) we propose a unified framework that enables symmetry discovery across a broad range of subgroups including locally symmetric, dihedral and cyclic subgroups. At the core of the framework is a novel architecture composed of linear and tensor-valued functions that expresses functions invariant to these subgroups in a principled manner. The structure of the architecture enables us to leverage multi-armed bandit algorithms and gradient descent to efficiently optimize over the linear and the tensor-valued functions respectively.</p>
<p>The following section is a brief overview of the recent advances in the theoretical analysis of push-forward generative models.</p>
<h3 id="Denoising Score Matching Langevin Dynamics">Denoising Score Matching Langevin Dynamics</h3>
<figure>
  <img src="/diffusion_models.png" alt=""/>
  <figcaption>Figure: Solving a reverse-time SDE yields a score-based
    generative model. Transforming data to a simple noise distribution can be accomplished
    with a continuous-time SDE.</figcaption>
</figure>
<p>Let <span
  class="math inline">\(p_\sigma(\tilde{\mathbf{x}} \mid
  \mathbf{x}):=\mathcal{N}\left(\tilde{\mathbf{x}} ; \mathbf{x}, \sigma^2
  \mathbf{I}\right)\)</span> , <span class="math inline">\(p_\sigma(\tilde{\mathbf{x}}):=\int p_{\text {data
  }}(\mathbf{x}) p_\sigma(\tilde{\mathbf{x}} \mid \mathbf{x}) \mathrm{d}
  \mathbf{x}\)</span>, where <span class="math inline">\(p_{\text {data
  }}(\mathbf{x})\)</span> denotes the data distribution. Consider a
  sequence of positive noise scales <span
  class="math inline">\(\sigma_{\min }=\sigma_1&lt;\)</span> <span
  class="math inline">\(\sigma_2&lt;\cdots&lt;\sigma_N=\sigma_{\max
  }\)</span>. Typically, <span class="math inline">\(\sigma_{\min
  }\)</span> is small enough such that <span
  class="math inline">\(p_{\sigma_{\min }}(\mathbf{x}) \approx p_{\text
  {data }}(\mathbf{x})\)</span>, and <span
  class="math inline">\(\sigma_{\max }\)</span> is large enough such that <span
  class="math inline">\(p_{\sigma_{\max }}(\mathbf{x}) \approx
  \mathcal{N}\left(\mathbf{x} ; \mathbf{0}, \sigma_{\max }^2
  \mathbf{I}\right)\)</span>. Song &amp; Ermon (2019) propose to train a
  Noise Conditional Score Network (NCSN), denoted by <span
  class="math inline">\(\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x},
  \sigma)\)</span>, with a weighted sum of denoising score matching
  (Vincent, 2011) objectives: <span
  class="math display">\[\boldsymbol{\theta}^*=\underset{\boldsymbol{\theta}}{\arg
  \min } \sum_{i=1}^N \sigma_i^2
  \mathbb{E}_{p_{\mathrm{data}}(\mathbf{x})}
  \mathbb{E}_{p_{\sigma_i}(\tilde{\mathbf{x}} \mid
  \mathbf{x})}\left[\left\|\mathbf{s}_{\boldsymbol{\theta}}\left(\tilde{\mathbf{x}},
  \sigma_i\right)-\nabla_{\tilde{\mathbf{x}}} \log
  p_{\sigma_i}(\tilde{\mathbf{x}} \mid \mathbf{x})\right\|_2^2\right]
  .\]</span> Given sufficient data and model capacity, the optimal
  score-based model <span class="math inline">\(\mathbf{s}_\theta
  *(\mathbf{x}, \sigma)\)</span> matches <span
  class="math inline">\(\nabla_{\mathbf{x}} \log
  p_\sigma(\mathbf{x})\)</span> almost everywhere for <span
  class="math inline">\(\sigma
  \in\left\{\sigma_i\right\}_{i=1}^N\)</span>. For sampling, Song &amp;
  Ermon (2019) run <span class="math inline">\(M\)</span> steps of
  Langevin MCMC to get a sample for each <span
  class="math inline">\(p_{\sigma_i}(\mathbf{x})\)</span> sequentially:
  <span
  class="math display">\[\mathbf{x}_i^m=\mathbf{x}_i^{m-1}+\epsilon_i
  \mathbf{s}_{\boldsymbol{\theta}^*}\left(\mathbf{x}_i^{m-1},
  \sigma_i\right)+\sqrt{2 \epsilon_i} \mathbf{z}_i^m, \quad m=1,2, \cdots,
  M,\]</span> where <span class="math inline">\(\epsilon_i&gt;0\)</span>
  is the step size, and <span
  class="math inline">\(\mathbf{z}_i^m\)</span> is standard normal. The
  above is repeated for <span class="math inline">\(i=N, N-\)</span> <span
  class="math inline">\(1, \cdots, 1\)</span> in turn with <span
  class="math inline">\(\mathbf{x}_N^0 \sim \mathcal{N}\left(\mathbf{x}
  \mid \mathbf{0}, \sigma_{\max }^2 \mathbf{I}\right)\)</span> and <span
  class="math inline">\(\mathbf{x}_i^0=\mathbf{x}_{i+1}^M\)</span> when
  <span class="math inline">\(i&lt;N\)</span>. As <span
  class="math inline">\(M \rightarrow \infty\)</span> and <span
  class="math inline">\(\epsilon_i \rightarrow 0\)</span> for all <span
  class="math inline">\(i, \mathbf{x}_1^M\)</span> becomes an exact sample
  from <span class="math inline">\(p_{\sigma_{\min }}(\mathbf{x}) \approx
  p_{\text {data }}(\mathbf{x})\)</span> under some regularity
  conditions.</p>
<figure>
  <img src="/authors/admin/DALLE-2-IMAGES.png" alt=""/>
  <figcaption>Figure: Selected samples from DALLE-2 model.</figcaption>
</figure>  
<h3 id="push-forward generative models">Push-forward generative models</h3>  
<p style="text-align:justify;">Score-Based Generative Modeling (SGM) is a recently developed approach to probabilistic generative modeling that exhibits state-of-the-art performance on several audio and image synthesis tasks. Progressively applying Gaussian noise transforms complex data distributions to approximately Gaussian. Reversing this dynamic defines a generative model. When the forward noising process is given by a Stochastic Differential Equation (SDE), <a href="https://arxiv.org/pdf/2011.13456.pdf"><em>Song et al. (2021)</em></a> demonstrate how the time inhomogeneous drift of the associated reverse-time SDE may be estimated using score-matching. A limitation of this approach is that the forward-time SDE must be run for a sufficiently long time for the final distribution to be approximately Gaussian while ensuring that the corresponding time-discretization error is controlled.</p>
<p>Theorem 1. Let <span class="math inline">\(g: \mathbb{R}^p
  \rightarrow \mathbb{R}^d\)</span> be a Lipschitz function with Lipschitz
  constant <span class="math inline">\(\operatorname{Lip}(g)\)</span>.
  Then for any Borel set <span class="math inline">\(\mathrm{A} \in
  \mathcal{B}\left(\mathbb{R}^d\right)\)</span>, <span
  class="math display">\[\operatorname{Lip}(g)\left(g_{\#}
  \mu_p\right)^{+}(\partial \mathrm{A}) \geq
  \varphi\left(\Phi^{-1}\left(g_{\#}
  \mu_p(\mathrm{~A})\right)\right)\]</span> where <span
  class="math inline">\(\varphi(x)=(2 \pi)^{-1 / 2} \exp \left[-x^2 /
  2\right]\)</span> and <span
  class="math inline">\(\Phi(x)=\int_{-\infty}^x \varphi(t) \mathrm{d}
  t\)</span>. In addition, we have that for any <span
  class="math inline">\(r \geq 0\)</span> <span
  class="math display">\[g_{\#} \mu_p\left(\mathrm{~A}_r\right) \geq
  \Phi\left(r / \operatorname{Lip}(g)+\Phi^{-1}\left(g_{\#}
  \mu_p(\mathrm{~A})\right)\right) \text {. }\]</span></p>
<p>Let <span class="math inline">\(\nu\)</span> be a probability measure
  on <span class="math inline">\(\mathbb{R}\)</span> with density w.r.t.
  the Lesbesgue measure and such that <span
  class="math inline">\(\operatorname{supp}(\nu)=\mathbb{R}\)</span>.
  Assume that there exists <span class="math inline">\(g: \mathbb{R}^p
  \rightarrow \mathbb{R}\)</span> Lipschitz such that <span
  class="math inline">\(\nu=g_{\#} \mu_p\)</span>. Let us denote <span
  class="math inline">\(T_{\mathrm{OT}}=\Phi_\nu^{-1} \circ \Phi\)</span>
  the Monge map between <span class="math inline">\(\mu_1\)</span> and
  <span class="math inline">\(\nu\)</span>, where <span
  class="math inline">\(\Phi_\nu\)</span> is the cumulative distribution
  function of <span class="math inline">\(\nu\)</span>. Then we have <span
  class="math inline">\(\operatorname{Lip}(g) \geq
  \operatorname{Lip}\left(T_{\mathrm{OT}}\right)\)</span>.</p>
<!--<p>We also do nitty-gritty research to make Gaussian processes (a model that is also common in statistics) work <em>really</em> well. One neat property of GPs is that there are principles for selecting all their free parameters. In principle, this means that humans aren&rsquo;t needed in the loop to train them.</p>-->
<!--<p>Unfortunately, to reduce computational complexity, approximations need to be introduced. These often introduce free parameters again, which then means that a human has to intervene to ensure that the quality of the approximation is acceptable. This defeats part of the point! We improved two GP approximations (variational and conjugate gradient) by providing:</p>-->
<!--<ul>
<li>automatic procedures for selecting approximation parameters, and</li>
<li>mathematical guarantees on the quality of the solution.</li>
</ul>-->
<h3 id="Poisson Flow Generative Models">Poisson Flow Generative Models</h3>
<figure>
  <img src="/authors/admin/Image2.png" alt=""/>
  <figcaption>Figure: (a) 3D Poisson field trajectories for a heart-shaped distribution (b) The evolvements of a
    distribution (top) or an (augmented) sample (bottom) by the forward/backward ODEs pertained to
    the Poisson field.</figcaption>
</figure>  
<p style="text-align:justify;">The Poisson flow generative model (PFGM) maps a uniform distribution
  on a high-dimensional hemisphere into any data distribution. They
  interpret the data points as electrical charges on the <span
  class="math inline">\(\mathrm{z}=\)</span> 0 hyperplane in a space
  augmented with an additional dimension z, generating a high-dimensional
  electric field (the gradient of the solution to Poisson equation). They
  prove that if these charges flow upward along electric field lines,
  their initial distribution in the <span
  class="math inline">\(\mathrm{z}=0\)</span> plane transforms into a
  distribution on the hemisphere of radius <span
  class="math inline">\(r\)</span> that becomes uniform in the <span
  class="math inline">\(r \rightarrow \infty\)</span> limit. To learn the
  bijective transformation, they estimate the normalized field in the
  augmented space.</p></p>
<p>See:</p>
<ul>
<li><a href="https://arxiv.org/pdf/2011.13456.pdf">Score-Based Generative Modeling through Stochastic Differential Equations</a></li>
<li><a href="https://arxiv.org/pdf/2206.14476.pdf">Can Push-forward Generative Models Fit Multimodal Distributions?</a>
</a></li>
</ul>
<p>In the search for faster GP approximations, I have also worked on variational bounds that <a href="/publication/vdw-2020-inv/">do not require matrix inverses to be computed</a>. While the maths works, getting the method to optimise quickly enough for it to actually provide a practical benefit is still difficult. I do think the results are neat, and that there is a lot more to be looked into here.</p>
<!--<h3 id="deep-gaussian-processes">Deep Gaussian processes</h3>
<p>Why is accurate Gaussian process inference important? Well, apart from GPs being useful for noisy and/or low-data tasks where quantifying uncertainty is important<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, GPs are also a different representation of a neural network layer. It seems that there are advantages in terms of the quality of approximate Bayesian inference when representing a layer as a GP rather than with weights. One key research question is whether thinking about neural network layers as GPs can help bring the benefits of Bayesian inference (uncertainty and automatic model selection) to deep neural networks.</p>
<p>The evidence of this comes from the very first papers on deep GPs by <a href="http://proceedings.mlr.press/v31/damianou13a.html" target="_blank" rel="noopener">Damianou &amp; Lawrence</a>, where the marginal likelihood estimate was already used for model selection. Simple inference methods keep this property, even as <a href="/publication/dutordoir-2020-dcgp/">deep GP models become more complex</a>.</p>
<p>Techniques that accomplish similar things for neural networks are only now being developed. However, in some ways the approaches in deep GPs are simpler and easier, even if they are computationally expensive. I think that there is a significant opportunity for both classes of models to benefit from each other&rsquo;s strengths. <a href="/publication/dutordoir-2021-relu/">Deep links between deep GPs and deep neural networks</a> are becoming clearer, and can provide a concrete way to get the best of both worlds.</p>-->
<!--<h3 id="capsules">Capsules</h3>
<p>I do believe that good model structure is the most important property for good performance. When I first heard Geoff Hinton&rsquo;s talk about capsule networks, I was very intrigued by the inductive bias specified by the network alone. In addition, there seems to be a lot of probabilistic inspiration behind the routing algorithm.</p>
<p>Together with Lewis Smith et al, we attempted to make a fully <a href="/publication/smith-2020-capsules/">probabilistic formulation</a> of capsule networks, which would allow routing to be derived directly from inference. Although our practical success was limited, the project did provide a lot of insight. I do still believe in the idea behind capsules and their link to probabilistic inference. Hopefully this won&rsquo;t be our last project on the topic.</p>-->
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>See <a href="http://www.inference.org.uk/mackay/itila/book.html" target="_blank" rel="noopener">David MacKay&rsquo;s excellent textbook</a> for a good intro.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Which is the case in many industrial and engineering problems.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

    </div>

    




























  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  

  

  
  <p class="powered-by">
    © 2021
  </p>
  

  
  






  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-modules" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
      

    

    
    
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.71e713848164e269bc250f377042949d.js"></script>

    






</body>
</html>
