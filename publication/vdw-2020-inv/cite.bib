@inproceedings{vdw2020inv,
 abstract = {In this work, we provide a variational lower bound that can be computed without expensive matrix operations like inversion. Our bound can be used as a drop-in replacement to the existing variational method of Hensman et al. (2013, 2015), and can therefore directly be applied in a wide variety of models, such as deep GPs (Damianou and Lawrence, 2013). We focus on the theoretical properties of this new bound, and show some initial experimental results for optimising this bound. We hope to realise the full promise in scalability that this new bound has in future work.},
 author = {van der Wilk, Mark and John, ST and Artemev, Artem and Hensman, James},
 booktitle = {Proceedings of The 2nd Symposium on Advances in Approximate Bayesian Inference},
 editor = {Zhang, Cheng and Ruiz, Francisco and Bui, Thang and Dieng, Adji Bousso and Liang, Dawen},
 month = {Jan},
 pages = {1--9},
 pdf = {http://proceedings.mlr.press/v118/wilk20a/wilk20a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Variational Gaussian Process Models without Matrix Inverses},
 url = {http://proceedings.mlr.press/v118/wilk20a.html},
 volume = {118},
 year = {2020}
}

